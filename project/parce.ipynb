{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь будет производится скачивание и парсинг данных с сайта auto.ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача: Оценка рыночной стоимости мотоцикла с пробегом \n",
    "\n",
    "Данные: https://moto.drom.ru/moskva/sale/ \n",
    "\n",
    "Целевая переменная: цена в рублях\n",
    "\n",
    "Признаки: \n",
    "1. Модель мотоцикла\n",
    "2. Пробег\n",
    "3. Класс \n",
    "4. Год выпуска \n",
    "5. Объем двигателя \n",
    "6. Число тактов \n",
    "7. Состояние \n",
    "8. Документы\n",
    "9. Город \n",
    "10. Дата публикации объявления "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как они будут называться в таблице, разделитель ',': \n",
    "\n",
    "0. price\n",
    "1. model\n",
    "2. mileage \n",
    "3. motorcycle_class\n",
    "4. year \n",
    "5. engine_capacity\n",
    "6. engine_strokes \n",
    "7. damaged\n",
    "8. documents\n",
    "9. city\n",
    "10. date "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм:\n",
    "1. Скачать все страницы (есть номер страницы, если забанят - знаю, откуда продолжить)\n",
    "2. Получить из них список ссылкок (просто парсинг)\n",
    "3. Потом идти по каждой ссылке (есть номер ссылки, если забанят - знаю, откуда продолжить)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Импорт библиотек</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Класс, описывающий мотоцикл</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Motorcycle:\n",
    "    def __init__(self, soup_motorcycle, index=None):\n",
    "        self.soup = soup_motorcycle\n",
    "        if (index is None):\n",
    "            self.index = 0\n",
    "        else:\n",
    "            self.index = index\n",
    "            \n",
    "        self.warning_string_ = \"Index: \" + str(self.index) + \"; Warning: \"\n",
    "        \n",
    "    def warning_(self, string):\n",
    "        print(self.warning_string_ + string)\n",
    "        \n",
    "    def parse_information(self):\n",
    "        self.price = self.get_price()\n",
    "        if (self.price is None):\n",
    "            self.warning_('price not found')\n",
    "            return False\n",
    "        \n",
    "        self.model = self.get_feature({\"data-field\" : \"model\"})\n",
    "        self.mileage = self.get_feature({\"data-field\" : \"motoMileage\"})\n",
    "        self.motorcycle_class = self.get_feature({\"data-field\" : \"motoBodyType\"})\n",
    "        self.year = self.get_feature({\"data-field\" : \"year\"})\n",
    "        self.engine_capacity = self.get_feature({\"data-field\" : \"displacement\"})\n",
    "        self.engine_strokes = self.get_feature({\"data-field\" : \"motoEngineType\"})\n",
    "        self.damaged = self.get_feature({\"data-field\" : \"motoDriveCondition\"})\n",
    "        self.documents = self.get_feature({\"data-field\" : \"hasDocuments\"})\n",
    "        self.city = self.get_feature({\"title\" : \"Выбранный город\"})\n",
    "        #self.date = self.get_feature({\"class\" : \"viewbull-header__actuality\"})\n",
    "        return True\n",
    "        \n",
    "    def get_price(self):\n",
    "        price = self.soup.select_one('span.viewbull-summary-price__value')\n",
    "        if (price is not None):\n",
    "            price = price.text.strip()\n",
    "        else:\n",
    "            price = None\n",
    "        return price\n",
    "    \n",
    "    def get_feature(self, attrs):\n",
    "        feature = self.soup.findAll(attrs=attrs)\n",
    "        if (len(feature) > 0):\n",
    "            feature = feature[0].text.strip()\n",
    "        else:\n",
    "            feature = None\n",
    "        return feature\n",
    "\n",
    "    def __repr__(self):\n",
    "         return \"Motorcycle class\"\n",
    "        \n",
    "    def __str__(self):\n",
    "        string = str(self.index) + ',' + str(self.price) + ',' + str(self.model) + ',' + \\\n",
    "                    str(self.mileage) + ',' + str(self.motorcycle_class) + ',' + \\\n",
    "                    str(self.year) + ',' + str(self.engine_capacity) + ',' + \\\n",
    "                    str(self.engine_strokes) + ',' + str(self.damaged) + ',' + \\\n",
    "                    str(self.documents) + ',' + str(self.city) #+ ',' + str(self.date)\n",
    "        return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Информация по подключению</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_template = 'https://moto.drom.ru'\n",
    "url_list = url_template + '/moskva/sale/?page='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сайт с прокси: http://spys.one/proxys/RU/\n",
    "\n",
    "headers = None\n",
    "proxies = None\n",
    "#proxies = { 'https': '5.53.19.82:56907' }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Вспомогательные функции для подключения</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(url_page, proxies=None, headers=None, sleep=False, sleep_seconds=5):\n",
    "    html_page = requests.get(url_page, proxies=proxies, headers=headers).content\n",
    "    soup = BeautifulSoup(html_page, 'html.parser')\n",
    "\n",
    "    if (sleep):\n",
    "        time.sleep(np.random.randint(sleep_seconds))\n",
    "          \n",
    "    return soup.select('.bulletinLink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_motorcycle_soup(url_motorcycle, proxies=None, headers=None, sleep=False, sleep_seconds=5):\n",
    "    html_motorcycle = requests.get(url_motorcycle, proxies=proxies, headers=headers).content\n",
    "    soup_motorcycle = BeautifulSoup(html_motorcycle, 'html.parser')\n",
    "\n",
    "    if (sleep):\n",
    "        time.sleep(np.random.randint(sleep_seconds))\n",
    "        \n",
    "    return soup_motorcycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Создание списка ссылок</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_page = 1\n",
    "last_page = 11\n",
    "current_link = 1\n",
    "\n",
    "with open('data/links.txt', 'a') as f_output:\n",
    "    for page in range(current_page, last_page+1):\n",
    "        links = get_links(url_list + str(page), proxies, headers, True)\n",
    "\n",
    "        if (links is None):\n",
    "            print(\"Error while getting motorcycle links\")\n",
    "            print(\"Page: \" + str(page))\n",
    "            print(\"Link: \" + str(current_link))\n",
    "            break\n",
    "\n",
    "        for link in links:\n",
    "            print(str(current_link) + '. ' + url_template + link['href'], file=f_output)\n",
    "            current_link += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Парсинг страниц с мотоциклами</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 4; Warning: price not found\n",
      "Error while parsing motorcycle information\n",
      "Link: https://moto.drom.ru/moskva/sale/oficialnyj-dilerskij-centr-legendarnyh-anglijskih-motociklov-triumph-64015122.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = \"id,price,model,mileage,motorcycle_class,year,engine_capacity,engine_strokes,damaged,documents,city\"\n",
    "\n",
    "with open('data/links.txt', 'r') as links_file:\n",
    "    with open('data/motorcycles.csv', 'a', encoding='utf-8') as motorcycle_file:\n",
    "        print(features, file=motorcycle_file)\n",
    "        for i, link in enumerate(links_file, 1):\n",
    "            link = link[link.find('h'):]\n",
    "            \n",
    "            soup = get_motorcycle_soup(link, proxies, headers, False)\n",
    "            if (soup is None):\n",
    "                print(\"Error while getting motorcycle information\")\n",
    "                print(\"Link: \" + str(link))\n",
    "                break\n",
    "\n",
    "            motorcycle = Motorcycle(soup, i)\n",
    "            if (motorcycle.parse_information()):\n",
    "                print(motorcycle, file=motorcycle_file)\n",
    "            else:\n",
    "                print(\"Error while parsing motorcycle information\")\n",
    "                print(\"Link: \" + str(link))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
